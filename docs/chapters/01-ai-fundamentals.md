---
title: "Chapter 1: AI Fundamentals"
description: "Understanding the engine behind the AI-Powered ID: LLMs, tokens, and the mechanics of generative intelligence."
tags: ["foundations", "LLMs", "technical"]
difficulty: "Intermediate"
last_reviewed: 2025-12-29
reading_time: 12 min
authors: ["Dustin Ober"]
---

![Diagram showing the relationship between LLMs, tokens, and the instructional designer as architect](../assets/chapter-01-cover.jpg)

# AI Fundamentals for Instructional Designers

In **[Chapter 0](00-introduction.md)**, we established the vision of the AI-powered instructional designer as a "Learning Architect." To fulfill that role, we must first understand the "engine" that powers our tools. This chapter demystifies Large Language Models (LLMs) and explains the core concepts that every instructional designer should know.

!!! tip "You Don't Need to Be Technical"
    You don't need to be a programmer to understand AI. Think of this chapter like learning how a car engine worksâ€”you don't need to be a mechanic to drive, but understanding the basics helps you drive better and troubleshoot problems.

---

## 1. What is an LLM?

A **Large Language Model** is a type of artificial intelligence trained on massive amounts of text data. It uses statistical patterns to predict the next word (or "token") in a sequence.

```mermaid
flowchart LR
    A[ðŸ“š Training Data<br>Books, Web, Code] --> B[ðŸ§  Neural Network<br>Billions of Parameters]
    B --> C[ðŸ”® Pattern Recognition<br>Statistical Predictions]
    C --> D[ðŸ’¬ Generated Text<br>Responses, Content]
```

> [!NOTE]
> Think of an LLM as a highly sophisticated "auto-complete" built on the sum of human digital knowledge.

For an ID, an LLM is more than a chatbot; it is a **reasoning engine**. It can:

| Capability | Example |
|------------|---------|
| **Synthesize information** | "Summarize these 5 research papers into key findings" |
| **Adopt personas** | "Act as a subject matter expert in physics" |
| **Format content** | "Generate a SCORM-compliant outline" |
| **Simulate conversations** | "Role-play as a frustrated customer for this scenario" |
| **Generate variations** | "Create 5 different ways to explain this concept" |

### The Evolution: ID to Learning Architect

As AI commoditizes content production (writing, coding, image generation), the Instructional Designer's role is shifting fundamentally:

```mermaid
flowchart LR
    subgraph OLD ["Traditional ID (80% Production)"]
        A1[Draft content]
        A2[Record audio]
        A3[Build slides]
        A4[Format outputs]
    end
    
    subgraph NEW ["Learning Architect (80% Strategy)"]
        B1[Design learning architecture]
        B2[Select & orchestrate AI agents]
        B3[Quality assure outputs]
        B4[Optimize learner experience]
    end
    
    OLD -->|AI Shift| NEW
```

| Aspect | Old Role | New Role |
|--------|----------|----------|
| **Time Allocation** | 80% creation, 20% strategy | 20% creation, 80% strategy |
| **Value Proposition** | Speed of hands-on-keyboard | Quality of thinking and curation |
| **Key Skill** | Software proficiency | Prompt engineering + judgment |

---

## 2. Tokens and Context Windows

Understanding how AI "reads" and "remembers" is crucial for effective prompting.

### Tokens: How AI Reads

AI doesn't read words like humans do. It breaks text into **tokens**â€”small chunks of characters.

```mermaid
flowchart LR
    A["'Instructional Design'"] --> B["Token 1: 'Instruct'"]
    A --> C["Token 2: 'ional'"]
    A --> D["Token 3: ' Design'"]
```

**Quick Reference:**

| Metric | Approximate Value |
|--------|------------------|
| 1,000 tokens | ~750 words |
| 1 page (single-spaced) | ~660 tokens |
| Average email | ~200 tokens |
| This chapter | ~2,500 tokens |

**Why does this matter?**

1. **Cost**: API pricing is based on tokens (input + output)
2. **Limits**: Models have maximum token limits per request
3. **Optimization**: More concise prompts = lower costs + faster responses

### Context Window: AI's Working Memory

The **context window** is how much information the model can "hold in its head" at once.

| Model (2025) | Context Window | Equivalent |
|--------------|----------------|------------|
| GPT-4 Turbo | 128K tokens | ~300 pages |
| Claude 3 | 200K tokens | ~500 pages |
| Gemini 1.5 Pro | 1M+ tokens | ~2,500 pages |

> [!TIP]
> Even with large context windows, relevance matters more than volume. A focused 500-word prompt often outperforms a rambling 5,000-word one.

---

## 3. Structuring Knowledge: Chaining vs. RAG

Two advanced techniques are essential for creating consistent, high-quality curriculum:

### Prompt Chaining

Breaking a complex task into a sequence of smaller, dependent prompts:

```mermaid
flowchart TD
    A[Prompt A: Generate outline] --> B[Prompt B: Draft Module 1]
    B --> C[Prompt C: Create quiz for Module 1]
    C --> D[Prompt D: Draft Module 2]
    D --> E[Continue...]
```

**Use Cases:**
- Generating a complete course (outline â†’ content â†’ assessments)
- Creating consistent character voices across a scenario
- Building complex documents section by section

### Retrieval-Augmented Generation (RAG)

Connecting the LLM to your specific "knowledge base" of approved documents:

```mermaid
flowchart LR
    A[Learner Question] --> B[RAG System]
    B --> C[(Knowledge Base<br>PDFs, Manuals, Policies)]
    C --> D[Relevant Chunks Retrieved]
    D --> E[LLM Generates Answer]
    E --> F[Grounded Response]
```

**Use Cases:**
- Compliance training that cites your actual policies
- Product training grounded in technical manuals
- Onboarding bots that answer from your employee handbook

> [!NOTE]
> **The Key Difference:**
> - Standard LLM: "What do I know about this topic generally?"
> - RAG-powered LLM: "What does YOUR document say about this specific question?"

---

## 4. Generative vs. Discriminative AI

Understanding the difference helps you choose the right tool:

| Type | What It Does | ID Use Cases |
|------|--------------|--------------|
| **Generative AI** | Creates new content based on patterns | Writing scenarios, generating quiz options, creating images |
| **Discriminative AI** | Classifies or analyzes existing data | Grading assessments, identifying skill gaps, sentiment analysis of feedback |

```mermaid
flowchart LR
    subgraph GEN ["Generative AI"]
        G1[Input: Prompt]
        G2[Output: New Content]
        G1 --> G2
    end
    
    subgraph DIS ["Discriminative AI"]
        D1[Input: Data]
        D2[Output: Classification/Score]
        D1 --> D2
    end
```

---

## 5. The AI Toolbox: Beyond ChatGPT

The AI landscape for instructional designers is vast. Here's a categorized overview:

### Content Creation & Writing

| Tool | Best For | Key Feature |
|------|----------|-------------|
| **ChatGPT** | General content, brainstorming | Widely adopted, large community |
| **Claude** | Long-form content, nuanced writing | Strong at following complex instructions |
| **Gemini** | Research + multimodal content | Integrated with Google Workspace |

### Multimedia Generation

| Category | Tools | Use Case |
|----------|-------|----------|
| **Video (AI Avatars)** | Synthesia, HeyGen, Colossyan | Talking head videos without filming |
| **Audio (TTS)** | ElevenLabs, WellSaid Labs, Murf.ai | Professional voiceovers in minutes |
| **Images** | Midjourney, DALL-E 3, Adobe Firefly | Custom graphics without designers |
| **Presentations** | Tome, Gamma, Beautiful.ai | Rapid slide generation |

### Research & Analysis

| Tool | Best For |
|------|----------|
| **Perplexity** | Research with citations |
| **Elicit / Consensus** | Academic paper analysis |
| **NotebookLM** | Analyzing your own documents |

> [!TIP]
> **Focus on categories, not brands.** Tools evolve rapidly. Learn to evaluate "AI Voice Generators" as a category, not just "ElevenLabs" specifically.

For a comprehensive reference, see **[Appendix C: AI Tools Reference](../appendix-tools.md)**.

---

## 6. Evaluating AI Tools: A Framework

With hundreds of new AI tools launching weekly, use this checklist:

```mermaid
flowchart TD
    A[New AI Tool] --> B{Privacy & Security?}
    B -->|Data trained on public| C[âš ï¸ Don't use for proprietary content]
    B -->|Data stays private| D{Accuracy Check}
    D --> E{Cost vs. ROI?}
    E --> F{Export Options?}
    F --> G{Accessibility?}
    G --> H[âœ… Evaluate in Pilot]
```

### The 5-Point Evaluation Checklist

| Criteria | Key Question | Red Flag |
|----------|-------------|----------|
| **ðŸ”’ Privacy** | Does this tool use my data to train models? | No clear privacy policy |
| **ðŸŽ¯ Accuracy** | How does it cite sources? Can I verify? | No source attribution |
| **ðŸ’° Cost/ROI** | Does time saved justify the cost? | Hidden usage costs |
| **ðŸ“¤ Export** | Can I get content into my LMS/tools? | Proprietary format lock-in |
| **â™¿ Accessibility** | Does output meet WCAG standards? | No accessibility features |

> [!TIP]
> **Start Small**: Pick *one* tool to solve *one* specific bottleneck (e.g., "I need faster audio narration"). Evaluate ROI for that single task before expanding.

---

## 7. The "Hallucination" Problem

**Hallucination** occurs when an AI confidently generates factually incorrect information. This is the #1 risk for IDs.

### Why Hallucinations Happen

```mermaid
flowchart TD
    A[AI predicts 'most likely' text] --> B[No external verification]
    B --> C[Confident but wrong output]
    C --> D[ðŸ˜± Incorrect training content]
```

### Mitigation Strategies

| Strategy | Implementation |
|----------|---------------|
| **Verify Everything** | Treat all AI outputs as drafts requiring fact-checking |
| **SME Review** | Mandatory subject matter expert sign-off for technical content |
| **Use RAG** | Ground responses in verified source documents |
| **Set Expectations** | View AI as creative partner, not source of truth |
| **Check Citations** | AI often invents fake referencesâ€”always verify |

!!! warning "Critical Rule"
    Never deploy AI-generated content in learning modules without rigorous human verification. Hallucinations in training can cause real-world harm.

### Common Hallucination Patterns

| Pattern | Example | How to Catch |
|---------|---------|--------------|
| **Fake citations** | Invented author names, journal titles | Search for cited source |
| **Confident statistics** | "Studies show 73%..." | Ask for source, verify independently |
| **Plausible nonsense** | Technically worded but factually wrong | SME review |
| **Outdated information** | Training data cutoff issues | Check recency of claims |

---

## 8. Ethical Considerations

As instructional designers, we have responsibilities to our learners:

### Bias

AI models inherit biases from training data. We must audit outputs:

| Bias Type | What to Check | Example |
|-----------|---------------|---------|
| **Gender** | Role assignments in scenarios | Are managers always "he"? |
| **Cultural** | Assumptions about norms | Western-centric examples? |
| **Age** | Stereotypes about generations | Ageist assumptions? |
| **Ability** | Assumptions about capacities | Ableist language? |

### Privacy

| Do âœ… | Don't âŒ |
|-------|---------|
| Use anonymized data | Input employee names/IDs |
| Test with synthetic data | Use real PII for testing |
| Check tool privacy policies | Assume privacy by default |

### Accessibility

AI can help with accessibilityâ€”but requires verification:

| AI Can Help | Human Must Verify |
|-------------|-------------------|
| Generate alt-text descriptions | Alt-text accuracy and context |
| Create transcripts | Transcript accuracy |
| Simplify reading level | Meaning preserved after simplification |
| Suggest color contrast | Actual compliance with WCAG |

### Academic Integrity

When using AI for assessments:

```mermaid
flowchart TD
    A[AI-Generated Assessment] --> B{SME Validation}
    B -->|Pass| C{Alignment Check}
    C -->|Aligned to Objectives| D{Bias Review}
    D -->|Clear| E[âœ… Use in Training]
    B -->|Fail| F[Revise with AI]
    C -->|Mismatch| F
    D -->|Bias Found| F
    F --> A
```

---

## Summary: Key Concepts at a Glance

| Concept | Definition | ID Application |
|---------|------------|----------------|
| **LLM** | AI trained on text to predict sequences | "Engine" behind all text generation |
| **Token** | Chunk of characters (~0.75 words) | Affects cost and context limits |
| **Context Window** | Model's "working memory" | How much you can include in prompts |
| **RAG** | LLM + your documents | Eliminates hallucinations on your content |
| **Prompt Chaining** | Sequence of dependent prompts | Complex projects broken into steps |
| **Hallucination** | AI generating false info confidently | Why verification is essential |

---

## Reflection Exercise: Creativity vs. Accuracy

**Goal**: Experience the tension between AI creativity and factual accuracy.

### Step 1: Generate Creative Analogies
Choose a topic you teach (e.g., "Fire Safety" or "Python Basics").

Prompt:
```
Generate three different creative analogies to explain [YOUR TOPIC] 
to a complete beginner with no background in this field.
```

### Step 2: Evaluate the Output

| Analogy | Engagement Score (1-5) | Accuracy Score (1-5) | Issues Found |
|---------|----------------------|---------------------|--------------|
| #1 | | | |
| #2 | | | |
| #3 | | | |

### Step 3: Reflect

??? question "Discussion Questions"
    - Which analogy was most "sticky" or memorable?
    - Did any analogy oversimplify to the point of creating misconceptions?
    - How would you edit the best analogy to fix accuracy issues?
    - What does this tell you about the AI's role in your workflow?

---

*References:*

- EDUCAUSE (2025). *2025 Horizon Report: Teaching and Learning Edition*.
- Malamed, C. (2025). *What AI Tools Are Instructional Designers Using?*. The eLearning Coach.
- Mollick, E. (2024). *Co-Intelligence: Living and Working with AI*. Portfolio.
- Moore, C. (2025). *Best AI Tools for Instructional Designers*.

---

### What's Next?

Now that you understand the mechanics of the LLM engine, it's time to learn how to drive it. In **[Chapter 2: Prompt Engineering](02-prompt-engineering.md)**, we will master the art and science of communicating with AI to get high-quality, pedagogically sound results every time.
